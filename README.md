<h1 align="center"> Hi, I'm Sumit Sharma</h1>

<p align="center">
<b>AI Researcher 路 Cognitive Intelligence 路 AI Safety</b><br>
Designing <b>transparent, safe, and cognitively grounded reasoning systems</b>.
</p>

---

##  Research Focus

I work at the intersection of **cognitive science, artificial intelligence, and AI safety**, with an emphasis on building systems that can **reason, explain, and align with human values**.

-  **Cognitive Intelligence Systems** (ACT-R / SOAR-inspired reasoning)
- З **AI Safety & Interpretability** (chain-of-thought monitoring, alignment)
- 锔 **High-Performance AI Systems** (CUDA, scalable learning & simulation)
-  **HumanAI Reasoning Transparency**

---

##  Current Work

### З Cognitive Assistant for Student Mental Health *(Research Prototype)*
A non-clinical cognitive AI system designed to:
- Infer **intent, emotion, and cognitive load**
- Reason using **cognitive architectures**
- Provide **transparent recommendations** (music, reading, reflection)

 Repository: *work in progress*  
 Research notes: *in preparation*

---

###  Chain-of-Thought Monitorability Framework (CoT-MF)
A technical AI safety framework to:
- Inspect internal reasoning traces of LLMs
- Detect hallucinations and unsafe reasoning paths
- Improve interpretability and auditability

 Repository: *in preparation*

---

##  Research Interests

- Cognitive AI & Reasoning Systems  
- Technical AI Safety & Alignment  
- Mechanistic Interpretability  
- High-Performance Computing for AI  
- HumanAI Interaction & Transparency  
- AI for Mental Health & Education  

---

## 锔 Tools & Technologies

**Languages & Frameworks**  
Python 路 PyTorch 路 TensorFlow 路 Hugging Face 路 CUDA  

**Systems & Libraries**  
Linux 路 OpenCV 路 NumPy 路 Pandas 路 Scikit-learn  

---

##  Connect

-  LinkedIn: https://linkedin.com/in/sumit45  
-  Email: sumit336sharma@gmail.com  

---

<p align="center">
<i>Building AI systems that reason, explain, and align.</i>
</p>
